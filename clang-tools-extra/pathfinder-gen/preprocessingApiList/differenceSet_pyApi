ASGD
AbsTransform
Adadelta
Adagrad
Adam
AdamW
Adamax
AdaptiveAvgPool1d
AdaptiveAvgPool2d
AdaptiveAvgPool3d
AdaptiveLogSoftmaxWithLoss
AdaptiveMaxPool1d
AdaptiveMaxPool2d
AdaptiveMaxPool3d
AffineTransform
AlphaDropout
AvgPool1d
AvgPool2d
AvgPool3d
BCELoss
BCEWithLogitsLoss
BFloat16Storage
Backend
BasePruningMethod
BatchNorm1d
BatchNorm2d
BatchNorm3d
BatchSampler
Bernoulli
Beta
Bilinear
Binomial
BoolStorage
BuildExtension
ByteStorage
C10dRendezvousBackend
CELU
CTCLoss
CUDAExtension
CallgrindStats
Categorical
Cauchy
ChainDataset
ChainedScheduler
ChannelShuffle
CharStorage
Chi2
ChildFailedError
ComplexDoubleStorage
ComplexFloatStorage
ComposeTransform
ConcatDataset
ConsoleMetricHandler
ConstantLR
ConstantPad1d
ConstantPad2d
ConstantPad3d
Constraint
ConstraintRegistry
ContinuousBernoulli
Conv1d
Conv2d
Conv3d
ConvTranspose1d
ConvTranspose2d
ConvTranspose3d
CorrCholeskyTransform
CosineAnnealingLR
CosineAnnealingWarmRestarts
CosineEmbeddingLoss
CosineSimilarity
CppExtension
CrossEntropyLoss
CustomFromMask
CyclicLR
DataLoader
DataParallel
Dataset
Directory
Dirichlet
DistributedDataParallel
DistributedSampler
Distribution
DoubleStorage
Dropout
Dropout2d
Dropout3d
DynamicRendezvousHandler
ELU
ElasticAgent
Embedding
EmbeddingBag
EmptyMatchError
ErrorHandler
EtcdRendezvousBackend
EtcdRendezvousHandler
EtcdServer
EtcdStore
Event
EventSource
ExpTransform
Exponential
ExponentialFamily
ExponentialLR
FeatureAlphaDropout
FileStore
FisherSnedecor
Flatten
FloatStorage
Fold
FractionalMaxPool2d
FractionalMaxPool3d
FunctionCounts
Future
GELU
GLU
GRU
GRUCell
Gamma
GaussianNLLLoss
Generator
Geometric
Graph
GraphModule
GroupNorm
Gumbel
HalfCauchy
HalfNormal
HalfStorage
Hardshrink
Hardsigmoid
Hardswish
Hardtanh
HashStore
HingeEmbeddingLoss
HuberLoss
Identity
Independent
IndependentTransform
InstanceNorm1d
InstanceNorm2d
InstanceNorm3d
IntStorage
Interpreter
IterableDataset
Join
JoinHook
Joinable
KLDivLoss
Kumaraswamy
L1Loss
L1Unstructured
LBFGS
LKJCholesky
LPPool1d
LPPool2d
LSTM
LSTMCell
LambdaLR
Laplace
LayerNorm
LazyBatchNorm1d
LazyBatchNorm2d
LazyBatchNorm3d
LazyConv1d
LazyConv2d
LazyConv3d
LazyConvTranspose1d
LazyConvTranspose2d
LazyConvTranspose3d
LazyInstanceNorm1d
LazyInstanceNorm2d
LazyInstanceNorm3d
LazyLinear
LazyModuleMixin
LeakyReLU
Linear
LinearLR
LnStructured
LocalElasticAgent
LocalResponseNorm
LocalTimerClient
LocalTimerServer
LogNormal
LogSigmoid
LogSoftmax
LogitRelaxedBernoulli
LongStorage
LowRankMultivariateNormal
LowerCholeskyTransform
MSELoss
MarginRankingLoss
MaxPool1d
MaxPool2d
MaxPool3d
MaxUnpool1d
MaxUnpool2d
MaxUnpool3d
Measurement
MetricHandler
Mish
MixtureSameFamily
Module
ModuleDict
ModuleList
MultiLabelMarginLoss
MultiLabelSoftMarginLoss
MultiMarginLoss
MultiStepLR
MultiheadAttention
Multinomial
MultiplicativeLR
MultiprocessContext
MultivariateNormal
NAdam
NLLLoss
NegativeBinomial
Node
Normal
NullMetricHandler
OneCycleLR
OneHotCategorical
Optimizer
PContext
PReLU
PackageExporter
PackageImporter
PackagingError
PackedSequence
PairwiseDistance
Parameter
ParameterDict
ParameterList
ParametrizationList
Pareto
PixelShuffle
PixelUnshuffle
Poisson
PoissonNLLLoss
PowerTransform
PrefixStore
ProcessFailure
ProfilerAction
ProfilerActivity
Proxy
PruningContainer
QInt32Storage
QInt8Storage
QUInt4x2Storage
QUInt8Storage
RAdam
RMSprop
RNN
RNNBase
RNNCell
RReLU
RandomSampler
RandomStructured
RandomUnstructured
ReLU
ReLU6
ReduceLROnPlateau
ReduceOp
ReflectionPad1d
ReflectionPad2d
ReflectionPad3d
RelaxedBernoulli
RelaxedOneHotCategorical
RendezvousBackend
RendezvousClosedError
RendezvousConnectionError
RendezvousError
RendezvousHandler
RendezvousHandlerRegistry
RendezvousParameters
RendezvousStateError
RendezvousTimeout
RendezvousTimeoutError
ReplicationPad1d
ReplicationPad2d
ReplicationPad3d
ReshapeTransform
Rprop
RunProcsResult
RunResult
SELU
SGD
Sampler
ScriptFunction
ScriptModule
Sequential
SequentialLR
SequentialSampler
ShortStorage
SiLU
Sigmoid
SigmoidTransform
SimpleElasticAgent
SmoothL1Loss
SobolEngine
SoftMarginLoss
Softmax
Softmax2d
SoftmaxTransform
Softmin
Softplus
Softshrink
Softsign
SparseAdam
StackTransform
StepLR
StickBreakingTransform
Store
StudentT
SubprocessContext
Subset
SubsetRandomSampler
SummaryWriter
SyncBatchNorm
TCPStore
Tanh
TanhTransform
Tanhshrink
TensorDataset
Threshold
Timer
TimerClient
TimerRequest
TimerServer
Tracer
Transform
TransformedDistribution
Transformer
TransformerDecoder
TransformerDecoderLayer
TransformerEncoder
TransformerEncoderLayer
TripletMarginLoss
TripletMarginWithDistanceLoss
Unflatten
Unfold
Uniform
UninitializedBuffer
UninitializedParameter
Upsample
UpsamplingBilinear2d
UpsamplingNearest2d
VonMises
Weibull
WeightedRandomSampler
Worker
WorkerGroup
WorkerSpec
WorkerState
ZeroPad2d
ZeroRedundancyOptimizer
_assert
absolute_
add_
addbmm_
addcdiv_
addcmul_
addmm_
addr_
affine_grid
all_gather
all_gather_multigpu
all_gather_object
all_reduce
all_reduce_multigpu
all_to_all
annotate
apply_
are_deterministic_algorithms_enabled
as_subclass
as_tensor
assert_close
atan2_
backward
baddbmm_
barrier
bernoulli_
bfloat16
bitwise_and_
bitwise_left_shift_
bitwise_not_
bitwise_or_
bitwise_right_shift_
bitwise_xor_
bool
broadcast
broadcast_multigpu
broadcast_object_list
broadcast_shapes
byte
cached
calculate_gain
cauchy_
char
check_compiler_abi_compatibility
checkpoint
checkpoint_sequential
cholesky_ex
clip_grad_norm_
clip_grad_value_
collect_all
compiled_with_cxx11_abi
cond
configure
constant_
contiguous
copy_
copysign_
cpu
create_backend
create_handler
cross_entropy
cuda
cumprod_
cumsum_
custom_from_mask
data_ptr
dense_dim
device
digamma_
dim
dirac_
div_
divide_
double
download_url_to_file
dropout2d
dropout3d
eig
eigh
eigvals
eigvalsh
element_size
enable_grad
entr
eq_
erfcx
erfinv_
expand
expand_as
expires
expit
exponential_
export
export_to_pretty_string
eye_
fft
fft2
fftfreq
fftn
fftshift
fill_diagonal_
float
float_power_
floor_divide_
fmod_
fold
fork
fork_rng
freeze
from_dlpack
from_numpy
frombuffer
gammainc
gammaincc
gammaln
gather_object
gaussian_nll_loss
ge_
geometric_
get_backend
get_default_dtype
get_device
get_dir
get_ignored_functions
get_logging_handler
get_num_interop_threads
get_num_threads
get_overridable_functions
get_rank
get_rng_state
get_testing_overrides
get_worker_info
get_world_size
global_unstructured
grad
greater_
greater_equal_
grid_sample
gt_
gumbel_softmax
half
handle_torch_function
has_torch_function
help
hfft
householder_product
hypot_
i0e
i1
i1e
ifft
ifft2
ifftn
ifftshift
igamma_
igammac_
ignore
ihfft
include_paths
index_add_
index_copy_
index_fill_
indices
inference_mode
init_process_group
initial_seed
int
interpolate
inv
inv_ex
irecv
irfft
irfft2
irfftn
is_available
is_contiguous
is_cuda
is_grad_enabled
is_in_onnx_export
is_inference_mode_enabled
is_initialized
is_leaf
is_meta
is_mpi_available
is_nccl_available
is_ninja_available
is_parametrized
is_pinned
is_pruned
is_quantized
is_set_to
is_shared
is_sparse
is_storage
is_tensor
is_tensor_like
is_tensor_method_or_property
is_torchelastic_launched
is_warn_always_enabled
isend
isinstance
item
kaiming_normal_
kaiming_uniform_
kl_divergence
l1_unstructured
le_
lerp_
less_
less_equal_
lgamma_
list
ln_structured
load
load_inline
load_state_dict_from_url
load_url
lobpcg
local_response_norm
log_normal_
logical_and_
logical_not_
logical_or_
logical_xor_
logsigmoid
long
lp_pool1d
lp_pool2d
lstsq
lt_
lu
make_tensor
manual_seed
map_
masked_fill_
masked_scatter_
matrix_norm
matrix_rank
max_unpool1d
monitored_barrier
mul_
multi_dot
multigammaln
multilabel_soft_margin_loss
multiply_
mvlgamma_
ndim
ndimension
ndtr
ndtri
ne_
nelement
new_empty
new_full
new_group
new_ones
new_tensor
new_zeros
nextafter_
no_grad
normal_
normalize
not_equal_
numpy
ones_
optimize_for_inference
optimize_for_mobile
orthogonal
orthogonal_
pack_padded_sequence
pack_sequence
pad_packed_sequence
parameters_to_vector
pca_lowrank
pin_memory
pinv
polygamma_
pow_
prof
profile
psi
put_
put_metric
qscheme
random_
random_split
random_structured
random_unstructured
record
record_stream
recv
reduce
reduce_multigpu
reduce_op
reduce_scatter
reduce_scatter_multigpu
register_custom_op_symbolic
register_hook
register_kl
register_module_backward_hook
register_module_forward_hook
register_module_forward_pre_hook
register_module_full_backward_hook
register_parametrization
remainder_
remove
remove_parametrizations
remove_spectral_norm
remove_weight_norm
renorm_
repeat
replace_pattern
requires_grad
requires_grad_
reshape_as
resize_
retain_grad
retains_grad
rfft
rfft2
rfftfreq
rfftn
save
scatter_
scatter_add_
scatter_object_list
schedule
script
script_if_tracing
seed
select_model_mode_for_export
send
set_
set_default_dtype
set_default_tensor_type
set_dir
set_flush_denormal
set_grad_enabled
set_num_interop_threads
set_num_threads
set_printoptions
set_rng_state
set_warn_always
sgn_
share_memory_
short
sign_
skip_init
softmin
softsign
solve
sparse_
sparse_dim
sparse_mask
spectral_norm
squeeze_
start_processes
storage
storage_offset
storage_type
sub_
subtract_
sum_to_size
svd_lowrank
svdvals
symbolic_trace
symeig
t_
tanhshrink
tensor
tensorboard_trace_handler
tensorinv
tensorsolve
to
to_dlpack
to_mkldnn
to_sparse
tolist
trace_module
transpose_
tril_
triplet_margin_with_distance_loss
triu_
true_divide_
type
type_as
unfold
uniform_
unique
unsqueeze_
unused
upsample
upsample_bilinear
upsample_nearest
use_deterministic_algorithms
values
vector_norm
vector_to_parameters
verify_ninja_availability
view
view_as
wait
wait_all
weight_norm
wrap
wrap_torch_function
xavier_normal_
xavier_uniform_
xlog1py
zeros_
zeta
